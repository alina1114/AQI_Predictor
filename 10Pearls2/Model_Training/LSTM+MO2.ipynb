{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d746e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Multi-horizon AQI with LSTM + Optuna (mirrors your LGBM pipeline) ===\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ----------------- Imports -----------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Torch (install on the fly if needed)\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "except ImportError:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torch\"])\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Optuna (install if needed)\n",
    "try:\n",
    "    import optuna\n",
    "except ImportError:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"optuna\"])\n",
    "    import optuna\n",
    "\n",
    "# SHAP (install if needed)\n",
    "try:\n",
    "    import shap\n",
    "except ImportError:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"shap\"])\n",
    "    import shap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9df6a6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ----------------- CONFIG (kept same style/paths) -----------------\n",
    "PROJECT_ROOT  = Path.cwd().parent        # notebook inside Model_training/\n",
    "DATA_PATH     = PROJECT_ROOT / \"preprocessed_aqi_data (3).csv\"\n",
    "FEATURES_JSON = PROJECT_ROOT / \"final_feature_list.json\"\n",
    "\n",
    "OUT_DIR       = PROJECT_ROOT / \"predictions\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_FILE   = OUT_DIR / \"lstm_predicted_aqi_72hrs.csv\"      # <— LSTM CSV (no overwrite of LGBM CSV)\n",
    "\n",
    "WINDOW_SIZE     = 24       # past hours per sample\n",
    "PREDICT_HORIZON = 72       # next 72 hours (3 days)\n",
    "TARGET_COL      = \"us_aqi\"\n",
    "TIME_COL_CANDS  = [\"time\", \"datetime\"]\n",
    "\n",
    "# Default training params (used for final retrain unless replaced by Optuna best)\n",
    "EPOCHS          = 40\n",
    "BATCH_SIZE      = 256\n",
    "LR              = 1e-3\n",
    "WD              = 1e-4\n",
    "PATIENCE        = 8\n",
    "HIDDEN_SIZE     = 128\n",
    "NUM_LAYERS      = 2\n",
    "DROPOUT         = 0.2\n",
    "BIDIRECTIONAL   = False\n",
    "\n",
    "RANDOM_SEED     = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef4670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------- LOAD & PARSE TIME (DAY-FIRST) -------------------\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# pick time column name automatically\n",
    "for c in TIME_COL_CANDS:\n",
    "    if c in df.columns:\n",
    "        TIME_COL = c\n",
    "        break\n",
    "else:\n",
    "    raise ValueError(f\"No datetime column found. Expected one of: {TIME_COL_CANDS}\")\n",
    "\n",
    "# clean & parse as day-first to match your “4/8/25 = 4 Aug 2025”\n",
    "raw_time = (\n",
    "    df[TIME_COL].astype(str)\n",
    "      .str.strip()\n",
    "      .str.replace(\"\\u00A0\", \" \", regex=False)\n",
    "      .str.replace(\"\\u202F\", \" \", regex=False)\n",
    ")\n",
    "df[TIME_COL] = pd.to_datetime(raw_time, dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "# sort chronologically\n",
    "df = df.sort_values(TIME_COL).reset_index(drop=True)\n",
    "\n",
    "# ------------------- FEATURES -------------------\n",
    "feat_cols = json.loads(FEATURES_JSON.read_text())\n",
    "missing = [c for c in feat_cols + [TARGET_COL, TIME_COL] if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns in data: {missing}\")\n",
    "\n",
    "# ------------------- Helper: build windows (sequence version) -------------------\n",
    "def build_sequences_limit(frame, features, target, window, horizon):\n",
    "    n = len(frame)\n",
    "    return n - window - horizon\n",
    "\n",
    "def build_sequences_seq(frame, features, target, window, horizon):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      X: (N, T, F) oldest→newest order\n",
    "      Y: (N, H)\n",
    "    \"\"\"\n",
    "    Xs, Ys = [], []\n",
    "    Xmat = frame[features].values\n",
    "    yvec = frame[target].values\n",
    "    n = len(frame)\n",
    "    limit = n - window - horizon\n",
    "    for i in range(limit):\n",
    "        Xs.append(Xmat[i:i+window])                        # (T, F)\n",
    "        Ys.append(yvec[i+window:i+window+horizon])         # (H,)\n",
    "    return np.asarray(Xs), np.asarray(Ys), limit\n",
    "\n",
    "# ------------------- TRAIN-ONLY WINSORIZATION + IMPUTE + SCALE -------------------\n",
    "limit = build_sequences_limit(df, feat_cols, TARGET_COL, WINDOW_SIZE, PREDICT_HORIZON)\n",
    "if limit <= 0:\n",
    "    raise ValueError(\"Not enough rows to make sliding windows. Add more data.\")\n",
    "\n",
    "# map “train windows” back to raw rows used by their inputs (same logic as your LGBM)\n",
    "train_windows = int(limit * 0.8)\n",
    "raw_end_for_train_inputs = (train_windows - 1) + WINDOW_SIZE\n",
    "raw_end_for_train_inputs = max(raw_end_for_train_inputs, WINDOW_SIZE)\n",
    "\n",
    "# Winsorize on TRAIN INPUT rows only\n",
    "numeric_feats = [c for c in feat_cols if pd.api.types.is_numeric_dtype(df[c])]\n",
    "low = df.loc[:raw_end_for_train_inputs, numeric_feats].quantile(0.01).to_dict()\n",
    "high = df.loc[:raw_end_for_train_inputs, numeric_feats].quantile(0.99).to_dict()\n",
    "for c in numeric_feats:\n",
    "    df[c] = df[c].clip(lower=low[c], upper=high[c])\n",
    "\n",
    "# Median impute using TRAIN INPUT rows only, then apply to all\n",
    "train_medians = df.loc[:raw_end_for_train_inputs, feat_cols].median(numeric_only=True).to_dict()\n",
    "df[feat_cols] = df[feat_cols].fillna(train_medians)\n",
    "\n",
    "# Scale features for LSTM (fit on TRAIN INPUT rows only)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df.loc[:raw_end_for_train_inputs, feat_cols].values)\n",
    "df[feat_cols] = scaler.transform(df[feat_cols].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20882379",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------- BUILD SEQUENCES AFTER CLEANING/SCALING -------------------\n",
    "X_seq, y_seq, limit = build_sequences_seq(df, feat_cols, TARGET_COL, WINDOW_SIZE, PREDICT_HORIZON)\n",
    "N, T, F = X_seq.shape\n",
    "H = y_seq.shape[1]\n",
    "assert T == WINDOW_SIZE and H == PREDICT_HORIZON\n",
    "\n",
    "# ------------------- TRAIN/VAL SPLIT (chronological 80/20) -------------------\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_seq, y_seq, test_size=0.2, shuffle=False\n",
    ")\n",
    "\n",
    "# ------------------- LSTM Model -------------------\n",
    "class LSTMForecast(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout, horizon, bidirectional=False):\n",
    "        super().__init__()\n",
    "        self.bidirectional = bidirectional\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "            batch_first=True,\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        out_dim = hidden_size * (2 if bidirectional else 1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(out_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, horizon)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):               # x: (B, T, F)\n",
    "        out, _ = self.lstm(x)           # (B, T, hidden*(1|2))\n",
    "        last = out[:, -1, :]            # last time step\n",
    "        return self.head(last)          # (B, horizon)\n",
    "\n",
    "# ------------------- Training helpers -------------------\n",
    "def make_loaders(Xtr, Ytr, Xva, Yva, bs):\n",
    "    train_dl = DataLoader(TensorDataset(\n",
    "        torch.tensor(Xtr, dtype=torch.float32),\n",
    "        torch.tensor(Ytr, dtype=torch.float32)\n",
    "    ), batch_size=bs, shuffle=False)\n",
    "    val_dl = DataLoader(TensorDataset(\n",
    "        torch.tensor(Xva, dtype=torch.float32),\n",
    "        torch.tensor(Yva, dtype=torch.float32)\n",
    "    ), batch_size=bs, shuffle=False)\n",
    "    return train_dl, val_dl\n",
    "\n",
    "def eval_loader(model, dl):\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dl:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            preds.append(model(xb).cpu().numpy())\n",
    "            trues.append(yb.cpu().numpy())\n",
    "    return np.vstack(preds), np.vstack(trues)\n",
    "\n",
    "def train_one(model, train_dl, val_dl, lr=1e-3, wd=1e-4, max_epochs=40, patience=8, verbose=True):\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3)\n",
    "\n",
    "    best = float(\"inf\"); best_state = None; wait = 0; best_epoch = 0\n",
    "    for ep in range(1, max_epochs+1):\n",
    "        model.train()\n",
    "        for xb, yb in train_dl:\n",
    "            xb = xb.to(device); yb = yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        # validate\n",
    "        vp, vt = eval_loader(model, val_dl)\n",
    "        val_mae = mean_absolute_error(vt, vp)\n",
    "        scheduler.step(val_mae)\n",
    "        if verbose:\n",
    "            print(f\"Epoch {ep:02d} | Val MAE: {val_mae:.4f}\")\n",
    "\n",
    "        if val_mae < best - 1e-4:\n",
    "            best = val_mae; wait = 0; best_epoch = ep\n",
    "            best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                if verbose: print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "    if best_state:\n",
    "        model.load_state_dict(best_state)\n",
    "    return best, best_epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1c41043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 01:01:02,459] A new study created in memory with name: no-name-5d9c97db-52fa-4ee3-9fb3-7d7c8ab41eac\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Optuna hyperparameter search ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54aac2ad94344ccebfda98d75d48673b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-08-12 01:01:29,656] Trial 0 finished with value: 4.446578025817871 and parameters: {'hidden_size': 128, 'num_layers': 1, 'dropout': 0.11742508365045984, 'lr': 0.0016613456824808538, 'batch_size': 128, 'bidirectional': False}. Best is trial 0 with value: 4.446578025817871.\n",
      "[I 2025-08-12 01:17:09,710] Trial 1 finished with value: 4.546783447265625 and parameters: {'hidden_size': 256, 'num_layers': 2, 'dropout': 0.1873687420594126, 'lr': 0.0011677292338861146, 'batch_size': 256, 'bidirectional': True}. Best is trial 0 with value: 4.446578025817871.\n",
      "[I 2025-08-12 01:17:44,448] Trial 2 finished with value: 4.948182106018066 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.11951547789558387, 'lr': 0.0018631851866771777, 'batch_size': 64, 'bidirectional': True}. Best is trial 0 with value: 4.446578025817871.\n",
      "[I 2025-08-12 01:18:04,964] Trial 3 finished with value: 4.6471171379089355 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.2987566853061946, 'lr': 0.0007702625305495494, 'batch_size': 128, 'bidirectional': False}. Best is trial 0 with value: 4.446578025817871.\n",
      "[I 2025-08-12 01:18:12,135] Trial 4 finished with value: 4.416440486907959 and parameters: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.11356818667316143, 'lr': 0.0007849434692229535, 'batch_size': 256, 'bidirectional': False}. Best is trial 4 with value: 4.416440486907959.\n",
      "[I 2025-08-12 01:23:59,225] Trial 5 finished with value: 4.508734703063965 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.15961470446025172, 'lr': 0.0005038423281993181, 'batch_size': 64, 'bidirectional': False}. Best is trial 4 with value: 4.416440486907959.\n",
      "[I 2025-08-12 01:24:14,166] Trial 6 finished with value: 4.4789557456970215 and parameters: {'hidden_size': 160, 'num_layers': 1, 'dropout': 0.19329469651469866, 'lr': 0.0007847835160981072, 'batch_size': 256, 'bidirectional': False}. Best is trial 4 with value: 4.416440486907959.\n",
      "[I 2025-08-12 01:31:32,566] Trial 7 finished with value: 4.574131488800049 and parameters: {'hidden_size': 192, 'num_layers': 2, 'dropout': 0.2282623055075649, 'lr': 0.0005179333108777706, 'batch_size': 256, 'bidirectional': True}. Best is trial 4 with value: 4.416440486907959.\n",
      "[I 2025-08-12 01:31:37,796] Trial 8 finished with value: 4.425267696380615 and parameters: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.1869254358741304, 'lr': 0.0006252229210571545, 'batch_size': 64, 'bidirectional': False}. Best is trial 4 with value: 4.416440486907959.\n",
      "[I 2025-08-12 01:32:30,125] Trial 9 finished with value: 4.331830978393555 and parameters: {'hidden_size': 256, 'num_layers': 1, 'dropout': 0.13301557735830305, 'lr': 0.0006858049987638136, 'batch_size': 256, 'bidirectional': True}. Best is trial 9 with value: 4.331830978393555.\n",
      "[I 2025-08-12 01:35:30,680] Trial 10 finished with value: 4.773996829986572 and parameters: {'hidden_size': 128, 'num_layers': 3, 'dropout': 0.39086113323635985, 'lr': 0.001213855244216421, 'batch_size': 256, 'bidirectional': True}. Best is trial 9 with value: 4.331830978393555.\n",
      "[I 2025-08-12 01:38:41,812] Trial 11 finished with value: 4.548547744750977 and parameters: {'hidden_size': 96, 'num_layers': 2, 'dropout': 0.10624848966266176, 'lr': 0.000846280885562846, 'batch_size': 256, 'bidirectional': True}. Best is trial 9 with value: 4.331830978393555.\n",
      "[I 2025-08-12 01:38:49,257] Trial 12 finished with value: 4.476279258728027 and parameters: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.27474622252756636, 'lr': 0.0006974362062369969, 'batch_size': 256, 'bidirectional': False}. Best is trial 9 with value: 4.331830978393555.\n",
      "[I 2025-08-12 01:45:08,690] Trial 13 finished with value: 4.823614597320557 and parameters: {'hidden_size': 160, 'num_layers': 2, 'dropout': 0.1493196088787315, 'lr': 0.0009903828352941135, 'batch_size': 256, 'bidirectional': True}. Best is trial 9 with value: 4.331830978393555.\n",
      "[I 2025-08-12 01:45:29,645] Trial 14 finished with value: 4.434001445770264 and parameters: {'hidden_size': 192, 'num_layers': 1, 'dropout': 0.33157887512805806, 'lr': 0.0006235110138890489, 'batch_size': 256, 'bidirectional': False}. Best is trial 9 with value: 4.331830978393555.\n",
      "[I 2025-08-12 01:46:06,091] Trial 15 finished with value: 4.527446746826172 and parameters: {'hidden_size': 96, 'num_layers': 2, 'dropout': 0.22708393118026166, 'lr': 0.0009582249106879046, 'batch_size': 128, 'bidirectional': True}. Best is trial 9 with value: 4.331830978393555.\n",
      "[I 2025-08-12 01:46:20,339] Trial 16 finished with value: 4.392454147338867 and parameters: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.14482364087666383, 'lr': 0.0012833047535614388, 'batch_size': 256, 'bidirectional': True}. Best is trial 9 with value: 4.331830978393555.\n",
      "[I 2025-08-12 02:13:29,094] Trial 17 finished with value: 4.539621829986572 and parameters: {'hidden_size': 256, 'num_layers': 3, 'dropout': 0.15946290607152344, 'lr': 0.0013871613258346494, 'batch_size': 256, 'bidirectional': True}. Best is trial 9 with value: 4.331830978393555.\n",
      "[I 2025-08-12 02:13:54,188] Trial 18 finished with value: 5.485241413116455 and parameters: {'hidden_size': 192, 'num_layers': 1, 'dropout': 0.22255063041834178, 'lr': 0.0014675754566169231, 'batch_size': 64, 'bidirectional': True}. Best is trial 9 with value: 4.331830978393555.\n",
      "[I 2025-08-12 02:17:58,918] Trial 19 finished with value: 4.667734622955322 and parameters: {'hidden_size': 128, 'num_layers': 2, 'dropout': 0.1532884064557405, 'lr': 0.0011908534235112866, 'batch_size': 128, 'bidirectional': True}. Best is trial 9 with value: 4.331830978393555.\n",
      "[I 2025-08-12 02:22:47,949] Trial 20 finished with value: 4.478856563568115 and parameters: {'hidden_size': 160, 'num_layers': 2, 'dropout': 0.3327474658148877, 'lr': 0.0010375209573277035, 'batch_size': 256, 'bidirectional': True}. Best is trial 9 with value: 4.331830978393555.\n",
      "[I 2025-08-12 02:22:56,540] Trial 21 finished with value: 4.561405181884766 and parameters: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.13145039850061593, 'lr': 0.0006276843187022483, 'batch_size': 256, 'bidirectional': False}. Best is trial 9 with value: 4.331830978393555.\n",
      "[I 2025-08-12 02:23:16,408] Trial 22 finished with value: 4.162674427032471 and parameters: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.13534940547942495, 'lr': 0.000883288376549956, 'batch_size': 256, 'bidirectional': True}. Best is trial 22 with value: 4.162674427032471.\n",
      "[I 2025-08-12 02:23:33,756] Trial 23 finished with value: 4.201573848724365 and parameters: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.18716550930518888, 'lr': 0.0009188130208004009, 'batch_size': 256, 'bidirectional': True}. Best is trial 22 with value: 4.162674427032471.\n",
      "[I 2025-08-12 02:23:51,646] Trial 24 finished with value: 4.1470136642456055 and parameters: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.18417823203008826, 'lr': 0.0009090543932872351, 'batch_size': 256, 'bidirectional': True}. Best is trial 24 with value: 4.1470136642456055.\n",
      "\n",
      "Best trial: 24\n",
      "Best value (Val MAE): 4.1470136642456055\n",
      "Best params: {'hidden_size': 96, 'num_layers': 1, 'dropout': 0.18417823203008826, 'lr': 0.0009090543932872351, 'batch_size': 256, 'bidirectional': True}\n",
      "\n",
      "=== Retraining best LSTM with Optuna params ===\n",
      "Epoch 01 | Val MAE: 76.3634\n",
      "Epoch 02 | Val MAE: 76.2136\n",
      "Epoch 03 | Val MAE: 75.7767\n",
      "Epoch 04 | Val MAE: 73.8083\n",
      "Epoch 05 | Val MAE: 66.5659\n",
      "Epoch 06 | Val MAE: 53.8239\n",
      "Epoch 07 | Val MAE: 35.6357\n",
      "Epoch 08 | Val MAE: 12.9401\n",
      "Epoch 09 | Val MAE: 9.3794\n",
      "Epoch 10 | Val MAE: 14.2555\n",
      "Epoch 11 | Val MAE: 5.6051\n",
      "Epoch 12 | Val MAE: 4.7113\n",
      "Epoch 13 | Val MAE: 4.1891\n",
      "Epoch 14 | Val MAE: 4.9299\n",
      "Epoch 15 | Val MAE: 4.8615\n",
      "Epoch 16 | Val MAE: 4.4071\n",
      "Epoch 17 | Val MAE: 4.6799\n",
      "Epoch 18 | Val MAE: 4.7688\n",
      "Epoch 19 | Val MAE: 4.7254\n",
      "Epoch 20 | Val MAE: 4.7738\n",
      "Epoch 21 | Val MAE: 4.8640\n",
      "Early stopping.\n",
      "Best epoch used: 13 | Best Val MAE saved: 4.1891\n",
      "\n",
      "=== Train Metrics (averaged over 72 horizons) ===\n",
      "MAE:  8.089\n",
      "RMSE: 10.938\n",
      "R²:   0.289\n",
      "First 12 horizons MAE: [5.882, 5.685, 5.525, 5.341, 5.257, 5.173, 5.099, 5.083, 5.063, 5.106, 5.081, 5.183]\n",
      "24h MAE: 6.630\n",
      "48h MAE: 9.378\n",
      "72h MAE: 11.201\n",
      "\n",
      "=== Validation Metrics (averaged over 72 horizons) ===\n",
      "MAE:  4.864\n",
      "RMSE: 5.825\n",
      "R²:   -0.156\n",
      "First 12 horizons MAE: [2.732, 2.636, 2.538, 2.471, 2.398, 2.388, 2.375, 2.407, 2.471, 2.552, 2.61, 2.681]\n",
      "24h MAE: 4.203\n",
      "48h MAE: 5.960\n",
      "72h MAE: 6.658\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------- OPTUNA: tune key LSTM hyperparams -------------------\n",
    "def objective(trial):\n",
    "    hidden_size = trial.suggest_categorical(\"hidden_size\", [96, 128, 160, 192, 256])\n",
    "    num_layers  = trial.suggest_int(\"num_layers\", 1, 3)\n",
    "    dropout     = trial.suggest_float(\"dropout\", 0.1, 0.4)\n",
    "    lr          = trial.suggest_float(\"lr\", 5e-4, 2e-3, log=True)\n",
    "    batch_size  = trial.suggest_categorical(\"batch_size\", [64, 128, 256])\n",
    "    bidir       = trial.suggest_categorical(\"bidirectional\", [False, True])\n",
    "\n",
    "    train_dl, val_dl = make_loaders(X_train, y_train, X_val, y_val, batch_size)\n",
    "    model = LSTMForecast(\n",
    "        input_size=F,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers,\n",
    "        dropout=dropout,\n",
    "        horizon=H,\n",
    "        bidirectional=bidir\n",
    "    ).to(device)\n",
    "\n",
    "    best_mae, _ = train_one(\n",
    "        model, train_dl, val_dl,\n",
    "        lr=lr, wd=WD, max_epochs=EPOCHS, patience=PATIENCE, verbose=False\n",
    "    )\n",
    "    trial.report(best_mae, 1)\n",
    "    return best_mae\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
    "pruner  = optuna.pruners.MedianPruner(n_warmup_steps=5)\n",
    "study = optuna.create_study(direction=\"minimize\", sampler=sampler, pruner=pruner)\n",
    "print(\"\\n=== Running Optuna hyperparameter search ===\")\n",
    "study.optimize(objective, n_trials=25, show_progress_bar=True)\n",
    "print(\"\\nBest trial:\", study.best_trial.number)\n",
    "print(\"Best value (Val MAE):\", study.best_value)\n",
    "print(\"Best params:\", study.best_params)\n",
    "\n",
    "# Extract best params (fall back to defaults if any missing)\n",
    "best_params = study.best_params\n",
    "HIDDEN_SIZE   = best_params.get(\"hidden_size\", HIDDEN_SIZE)\n",
    "NUM_LAYERS    = best_params.get(\"num_layers\", NUM_LAYERS)\n",
    "DROPOUT       = best_params.get(\"dropout\", DROPOUT)\n",
    "LR            = best_params.get(\"lr\", LR)\n",
    "BATCH_SIZE    = best_params.get(\"batch_size\", BATCH_SIZE)\n",
    "BIDIRECTIONAL = best_params.get(\"bidirectional\", BIDIRECTIONAL)\n",
    "\n",
    "# ------------------- Retrain best LSTM on the same split, then evaluate/save -------------------\n",
    "print(\"\\n=== Retraining best LSTM with Optuna params ===\")\n",
    "train_dl, val_dl = make_loaders(X_train, y_train, X_val, y_val, BATCH_SIZE)\n",
    "model = LSTMForecast(F, HIDDEN_SIZE, NUM_LAYERS, DROPOUT, H, bidirectional=BIDIRECTIONAL).to(device)\n",
    "best_val_mae, best_epoch = train_one(\n",
    "    model, train_dl, val_dl, lr=LR, wd=WD, max_epochs=EPOCHS, patience=PATIENCE, verbose=True\n",
    ")\n",
    "print(f\"Best epoch used: {best_epoch} | Best Val MAE saved: {best_val_mae:.4f}\")\n",
    "\n",
    "# Final metrics (Train + Val)\n",
    "train_pred, train_true = eval_loader(model, train_dl)\n",
    "val_pred,   val_true   = eval_loader(model, val_dl)\n",
    "\n",
    "def metrics_block(y_t, y_p, label):\n",
    "    mae  = mean_absolute_error(y_t, y_p)\n",
    "    rmse = mean_squared_error(y_t, y_p, squared=False)\n",
    "    r2s  = [r2_score(y_t[:, h], y_p[:, h]) for h in range(H)]\n",
    "    print(f\"\\n=== {label} Metrics (averaged over {H} horizons) ===\")\n",
    "    print(f\"MAE:  {mae:.3f}\")\n",
    "    print(f\"RMSE: {rmse:.3f}\")\n",
    "    print(f\"R²:   {np.mean(r2s):.3f}\")\n",
    "    mae_list  = [mean_absolute_error(y_t[:, h], y_p[:, h]) for h in range(H)]\n",
    "    if H >= 12: print(f\"First 12 horizons MAE: {[round(m,3) for m in mae_list[:12]]}\")\n",
    "    if H >= 24: print(f\"24h MAE: {mae_list[23]:.3f}\")\n",
    "    if H >= 48: print(f\"48h MAE: {mae_list[47]:.3f}\")\n",
    "    if H >= 72: print(f\"72h MAE: {mae_list[71]:.3f}\")\n",
    "    return mae_list, r2s\n",
    "\n",
    "train_mae_list, train_r2_list = metrics_block(train_true, train_pred, \"Train\")\n",
    "val_mae_list,   val_r2_list   = metrics_block(val_true,   val_pred,   \"Validation\")\n",
    "\n",
    "# Save per-horizon validation metrics\n",
    "pd.DataFrame({\n",
    "    \"horizon\": np.arange(1, H+1),\n",
    "    \"MAE\": val_mae_list,\n",
    "    \"R2\":  val_r2_list\n",
    "}).to_csv(OUT_DIR / \"lstm_val_per_horizon_metrics.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88df5271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved forecast → d:\\Desktop\\AlinasPrograms\\myenv\\10Pearls2\\predictions\\lstm_predicted_aqi_72hrs.csv\n",
      "First/last timestamps: 10/8/25 00:00 → 12/8/25 23:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------- FORECAST NEXT 72 HOURS (ONE CSV) -------------------\n",
    "# last window of *scaled* features (after cleaning)\n",
    "last_window = df[feat_cols].values[-WINDOW_SIZE:]              # (T, F)\n",
    "last_window_t = torch.tensor(last_window, dtype=torch.float32).unsqueeze(0).to(device)  # (1, T, F)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    future_pred = model(last_window_t).cpu().numpy().reshape(-1)   # (72,)\n",
    "\n",
    "# anchor = last non-NaT time; start = +1 hour\n",
    "last_valid_time = df.loc[df[TIME_COL].notna(), TIME_COL].iloc[-1]\n",
    "start = last_valid_time.floor(\"H\") + pd.Timedelta(hours=1)\n",
    "future_times = pd.date_range(start=start, periods=PREDICT_HORIZON, freq=\"h\")\n",
    "\n",
    "# format as d/m/yy HH:MM (so 9/8/25 = 9 Aug 2025)\n",
    "ft = pd.Series(future_times)\n",
    "formatted_dt = (\n",
    "    ft.dt.day.astype(str) + \"/\" +\n",
    "    ft.dt.month.astype(str) + \"/\" +\n",
    "    ft.dt.strftime(\"%y\") + \" \" +\n",
    "    ft.dt.strftime(\"%H:%M\")\n",
    ")\n",
    "\n",
    "forecast_df = pd.DataFrame({\n",
    "    \"datetime\": formatted_dt,\n",
    "    \"predicted_aqi_us\": future_pred\n",
    "})\n",
    "forecast_df.to_csv(OUTPUT_FILE, index=False)\n",
    "print(f\"\\nSaved forecast → {OUTPUT_FILE}\")\n",
    "print(\"First/last timestamps:\", forecast_df['datetime'].iloc[0], \"→\", forecast_df['datetime'].iloc[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e369e146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model   → d:\\Desktop\\AlinasPrograms\\myenv\\10Pearls2\\models\\current\\lstm_multioutput_72h.pt\n",
      "Saved scaler  → d:\\Desktop\\AlinasPrograms\\myenv\\10Pearls2\\models\\current\\scaler_lstm.joblib\n",
      "Saved metadata→ d:\\Desktop\\AlinasPrograms\\myenv\\10Pearls2\\models\\current\\metadata_lstm.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ------------------- SAVE MODEL + METADATA + SCALER -------------------\n",
    "SAVE_DIR = PROJECT_ROOT / \"models\" / \"current\"\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "MODEL_PATH   = SAVE_DIR / \"lstm_multioutput_72h.pt\"\n",
    "SCALER_PATH  = SAVE_DIR / \"scaler_lstm.joblib\"\n",
    "META_PATH    = SAVE_DIR / \"metadata_lstm.json\"   # <— separate file to avoid overwriting LGBM metadata\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_PATH)\n",
    "joblib.dump(scaler, SCALER_PATH)\n",
    "\n",
    "meta = {\n",
    "    \"features\": feat_cols,                 # list of feature column names\n",
    "    \"target_col\": TARGET_COL,              # \"us_aqi\"\n",
    "    \"time_col\": TIME_COL,                  # e.g. \"time\" or \"datetime\"\n",
    "    \"window_size\": WINDOW_SIZE,            # 24\n",
    "    \"horizon\": PREDICT_HORIZON,            # 72\n",
    "    \"dayfirst\": True,                      # parse like 4/8/25 -> 4 Aug\n",
    "    \"winsor_low\": low,                     # 1% caps computed on train inputs\n",
    "    \"winsor_high\": high,                   # 99% caps\n",
    "    \"train_medians\": train_medians,        # feature medians (train inputs)\n",
    "    \"scaler_path\": str(SCALER_PATH),       # saved scaler\n",
    "    \"optuna_best\": study.best_params,      # tuned hyperparams\n",
    "}\n",
    "META_PATH.write_text(json.dumps(meta, indent=2))\n",
    "\n",
    "print(\"Saved model   →\", MODEL_PATH)\n",
    "print(\"Saved scaler  →\", SCALER_PATH)\n",
    "print(\"Saved metadata→\", META_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

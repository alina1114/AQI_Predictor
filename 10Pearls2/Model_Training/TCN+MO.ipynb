{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12736318,"sourceType":"datasetVersion","datasetId":8050683}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:39:11.456602Z","iopub.execute_input":"2025-08-11T17:39:11.457273Z","iopub.status.idle":"2025-08-11T17:39:11.777873Z","shell.execute_reply.started":"2025-08-11T17:39:11.457234Z","shell.execute_reply":"2025-08-11T17:39:11.777129Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/preprocessed-aqi-data-3/preprocessed_aqi_data (3).csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# === Multi-horizon AQI Forecasting with TCN (Kaggle-ready, start→finish) ===\nfrom pathlib import Path\nimport json, warnings\nwarnings.filterwarnings(\"ignore\")\n\n# ----------------- Imports -----------------\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler\nimport joblib\nimport matplotlib.pyplot as plt\n\n# Torch (Kaggle already has torch)\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.nn.utils import weight_norm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:39:11.779191Z","iopub.execute_input":"2025-08-11T17:39:11.779613Z","iopub.status.idle":"2025-08-11T17:39:16.594567Z","shell.execute_reply.started":"2025-08-11T17:39:11.779590Z","shell.execute_reply":"2025-08-11T17:39:16.593532Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# ----------------- CONFIG (Kaggle-aware) -----------------\nWINDOW_SIZE     = 24       # past hours per sample\nPREDICT_HORIZON = 72       # next 72 hours (3 days)\nTARGET_COL      = \"us_aqi\"\nTIME_COL_CANDS  = [\"time\", \"datetime\"]\n\n# Training\nEPOCHS          = 50\nBATCH_SIZE      = 256\nLR              = 2e-3\nWD              = 1e-4\nPATIENCE        = 8\nDROPOUT         = 0.25\nCHANNELS        = [128, 128, 128, 128]   # dilations 1,2,4,8 -> receptive field 31 (>24)\nKERNEL_SIZE     = 3\nRANDOM_SEED     = 42\n\n# Paths (auto-detect Kaggle)\nIS_KAGGLE = Path(\"/kaggle\").exists()\nif IS_KAGGLE:\n    INPUT_ROOT = Path(\"/kaggle/input/preprocessed-aqi-data-3\")\n    DATA_PATH = INPUT_ROOT / \"preprocessed_aqi_data (3).csv\"     # <— your file\n    FEATURES_JSON_PATH = INPUT_ROOT / \"final_feature_list.json\"  # add to dataset if you have it\n    OUT_DIR  = Path(\"/kaggle/working/predictions\")\n    SAVE_DIR = Path(\"/kaggle/working/models/current\")\nelse:\n    PROJECT_ROOT = Path.cwd().parent\n    DATA_PATH = PROJECT_ROOT / \"preprocessed_aqi_data (3).csv\"\n    FEATURES_JSON_PATH = PROJECT_ROOT / \"final_feature_list.json\"\n    OUT_DIR  = PROJECT_ROOT / \"predictions\"\n    SAVE_DIR = PROJECT_ROOT / \"models\" / \"current\"\n\nOUT_DIR.mkdir(parents=True, exist_ok=True)\nSAVE_DIR.mkdir(parents=True, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:39:16.595560Z","iopub.execute_input":"2025-08-11T17:39:16.596078Z","iopub.status.idle":"2025-08-11T17:39:16.603615Z","shell.execute_reply.started":"2025-08-11T17:39:16.596043Z","shell.execute_reply":"2025-08-11T17:39:16.602711Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ----------------- Reproducibility & Device -----------------\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device:\", device)\n\n# ------------------- LOAD & PARSE TIME (DAY-FIRST) -------------------\ndf = pd.read_csv(DATA_PATH)\n\n# pick time column name automatically\nfor c in TIME_COL_CANDS:\n    if c in df.columns:\n        TIME_COL = c\n        break\nelse:\n    raise ValueError(f\"No datetime column found. Expected one of: {TIME_COL_CANDS}\")\n\n# clean & parse as day-first (e.g., 4/8/25 -> 4 Aug 2025)\nraw_time = (\n    df[TIME_COL].astype(str)\n      .str.strip()\n      .str.replace(\"\\u00A0\", \" \", regex=False)\n      .str.replace(\"\\u202F\", \" \", regex=False)\n)\ndf[TIME_COL] = pd.to_datetime(raw_time, dayfirst=True, errors=\"coerce\")\n\n# sort chronologically\ndf = df.sort_values(TIME_COL).reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:39:16.604536Z","iopub.execute_input":"2025-08-11T17:39:16.604801Z","iopub.status.idle":"2025-08-11T17:39:16.790175Z","shell.execute_reply.started":"2025-08-11T17:39:16.604782Z","shell.execute_reply":"2025-08-11T17:39:16.789265Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# ------------------- FEATURE LIST -------------------\nif FEATURES_JSON_PATH.exists():\n    feat_cols = json.loads(FEATURES_JSON_PATH.read_text())\n    print(f\"Loaded {len(feat_cols)} features from final_feature_list.json\")\nelse:\n    print(\"⚠️ final_feature_list.json not found; inferring numeric features automatically.\")\n    feat_cols = [c for c in df.columns if c not in [TARGET_COL, TIME_COL] and pd.api.types.is_numeric_dtype(df[c])]\n    print(f\"Inferred {len(feat_cols)} numeric features.\")\n\nmissing = [c for c in feat_cols + [TARGET_COL, TIME_COL] if c not in df.columns]\nif missing:\n    raise ValueError(f\"Missing columns in data: {missing}\")\n\n# ------------------- Helpers: build windows -------------------\ndef build_sequences_limit(frame, features, target, window, horizon):\n    n = len(frame)\n    return n - window - horizon\n\ndef build_sequences_seq(frame, features, target, window, horizon):\n    \"\"\"\n    Returns:\n      X: (N, T, F) with oldest->newest order (T==window)\n      Y: (N, H)\n    \"\"\"\n    Xs, Ys = [], []\n    Xmat = frame[features].values\n    yvec = frame[target].values\n    n = len(frame)\n    limit = n - window - horizon\n    for i in range(limit):\n        Xs.append(Xmat[i:i+window])                        # (T, F)\n        Ys.append(yvec[i+window:i+window+horizon])         # (H,)\n    return np.asarray(Xs), np.asarray(Ys), limit","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:39:16.792214Z","iopub.execute_input":"2025-08-11T17:39:16.792642Z","iopub.status.idle":"2025-08-11T17:39:16.804227Z","shell.execute_reply.started":"2025-08-11T17:39:16.792621Z","shell.execute_reply":"2025-08-11T17:39:16.803487Z"}},"outputs":[{"name":"stdout","text":"⚠️ final_feature_list.json not found; inferring numeric features automatically.\nInferred 52 numeric features.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# ------------------- TRAIN-ONLY WINSORIZATION + IMPUTE + SCALE -------------------\nlimit = build_sequences_limit(df, feat_cols, TARGET_COL, WINDOW_SIZE, PREDICT_HORIZON)\nif limit <= 0:\n    raise ValueError(\"Not enough rows to make sliding windows. Add more data.\")\n\ntrain_windows = int(limit * 0.8)\nraw_end_for_train_inputs = (train_windows - 1) + WINDOW_SIZE\nraw_end_for_train_inputs = max(raw_end_for_train_inputs, WINDOW_SIZE)\n\n# Winsorize on TRAIN INPUT rows only (1%/99%)\nnumeric_feats = [c for c in feat_cols if pd.api.types.is_numeric_dtype(df[c])]\nlow = df.loc[:raw_end_for_train_inputs, numeric_feats].quantile(0.01).to_dict()\nhigh = df.loc[:raw_end_for_train_inputs, numeric_feats].quantile(0.99).to_dict()\nfor c in numeric_feats:\n    df[c] = df[c].clip(lower=low[c], upper=high[c])\n\n# Median impute using TRAIN INPUT rows only\ntrain_medians = df.loc[:raw_end_for_train_inputs, feat_cols].median(numeric_only=True).to_dict()\ndf[feat_cols] = df[feat_cols].fillna(train_medians)\n\n# Scale (fit on TRAIN INPUT rows only)\nscaler = StandardScaler()\nscaler.fit(df.loc[:raw_end_for_train_inputs, feat_cols].values)\ndf[feat_cols] = scaler.transform(df[feat_cols].values)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:39:16.805228Z","iopub.execute_input":"2025-08-11T17:39:16.806087Z","iopub.status.idle":"2025-08-11T17:39:16.929312Z","shell.execute_reply.started":"2025-08-11T17:39:16.806066Z","shell.execute_reply":"2025-08-11T17:39:16.928728Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# ------------------- BUILD SEQUENCES AFTER CLEANING/SCALING -------------------\nX_seq, y_seq, limit = build_sequences_seq(df, feat_cols, TARGET_COL, WINDOW_SIZE, PREDICT_HORIZON)\nN, T, F = X_seq.shape\nH = y_seq.shape[1]\nassert T == WINDOW_SIZE and H == PREDICT_HORIZON\nprint(f\"Windows: {N}, Window={T}, Features={F}, Horizon={H}\")\n\n# ------------------- TRAIN/VAL SPLIT (chronological 80/20) -------------------\nX_train, X_val, y_train, y_val = train_test_split(\n    X_seq, y_seq, test_size=0.2, shuffle=False\n)\n\n# ------------------- TCN MODEL -------------------\nclass CausalConv1d(nn.Module):\n    \"\"\"Left-pad only, to keep causality.\"\"\"\n    def __init__(self, in_ch, out_ch, kernel_size, dilation):\n        super().__init__()\n        pad = (kernel_size - 1) * dilation\n        self.pad = nn.ConstantPad1d((pad, 0), 0.0)\n        self.conv = weight_norm(nn.Conv1d(in_ch, out_ch, kernel_size,\n                                          dilation=dilation, padding=0))\n    def forward(self, x):  # x: (B, C, L)\n        return self.conv(self.pad(x))\n\nclass TemporalBlock(nn.Module):\n    def __init__(self, in_ch, out_ch, kernel_size, dilation, dropout):\n        super().__init__()\n        self.net = nn.Sequential(\n            CausalConv1d(in_ch, out_ch, kernel_size, dilation),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n            CausalConv1d(out_ch, out_ch, kernel_size, dilation),\n            nn.ReLU(),\n            nn.Dropout(dropout),\n        )\n        self.downsample = nn.Conv1d(in_ch, out_ch, 1) if in_ch != out_ch else None\n    def forward(self, x):\n        out = self.net(x)\n        res = x if self.downsample is None else self.downsample(x)\n        return torch.relu(out + res)\n\nclass TCN(nn.Module):\n    def __init__(self, in_feats, channels, kernel_size, dropout, horizon):\n        super().__init__()\n        layers = []\n        prev_c = in_feats\n        for i, c in enumerate(channels):\n            dilation = 2 ** i\n            layers.append(TemporalBlock(prev_c, c, kernel_size, dilation, dropout))\n            prev_c = c\n        self.tcn = nn.Sequential(*layers)\n        self.head = nn.Sequential(\n            nn.Linear(channels[-1], 256),\n            nn.ReLU(),\n            nn.Linear(256, horizon)\n        )\n    def forward(self, x):              # x: (B, T, F)\n        x = x.permute(0, 2, 1)         # -> (B, F, T)\n        y = self.tcn(x)                # (B, C, T)\n        last = y[:, :, -1]             # last time step (B, C)\n        return self.head(last)         # (B, horizon)\n\nmodel = TCN(F, CHANNELS, KERNEL_SIZE, DROPOUT, H).to(device)\ncriterion = nn.SmoothL1Loss()   # Huber\noptimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=3)\n\n# DataLoaders\ntrain_dl = DataLoader(TensorDataset(\n    torch.tensor(X_train, dtype=torch.float32),\n    torch.tensor(y_train, dtype=torch.float32)\n), batch_size=BATCH_SIZE, shuffle=False)\n\nval_dl = DataLoader(TensorDataset(\n    torch.tensor(X_val, dtype=torch.float32),\n    torch.tensor(y_val, dtype=torch.float32)\n), batch_size=BATCH_SIZE, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:39:16.930092Z","iopub.execute_input":"2025-08-11T17:39:16.930302Z","iopub.status.idle":"2025-08-11T17:39:20.117049Z","shell.execute_reply.started":"2025-08-11T17:39:16.930286Z","shell.execute_reply":"2025-08-11T17:39:20.116352Z"}},"outputs":[{"name":"stdout","text":"Windows: 2208, Window=24, Features=52, Horizon=72\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"best_val_mae = float(\"inf\")\nbest_state = None\nwait = 0\n\ndef eval_loader(dataloader):\n    model.eval()\n    preds, trues = [], []\n    with torch.no_grad():\n        for xb, yb in dataloader:\n            xb = xb.to(device); yb = yb.to(device)\n            pred = model(xb)\n            preds.append(pred.cpu().numpy())\n            trues.append(yb.cpu().numpy())\n    return np.vstack(preds), np.vstack(trues)\n\nfor ep in range(1, EPOCHS+1):\n    model.train()\n    for xb, yb in train_dl:\n        xb = xb.to(device); yb = yb.to(device)\n        optimizer.zero_grad()\n        pred = model(xb)\n        loss = criterion(pred, yb)\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=2.0)  # ← fixed\n        optimizer.step()\n\n    # Validate\n    val_pred, val_true = eval_loader(val_dl)\n    val_mae  = mean_absolute_error(val_true, val_pred)\n    scheduler.step(val_mae)\n    print(f\"Epoch {ep:02d} | Val MAE: {val_mae:.4f}\")\n\n    if val_mae < best_val_mae - 1e-4:\n        best_val_mae = val_mae\n        best_state = {k: v.cpu() for k, v in model.state_dict().items()}\n        wait = 0\n    else:\n        wait += 1\n        if wait >= PATIENCE:\n            print(\"Early stopping.\")\n            break\n\nif best_state:\n    model.load_state_dict(best_state)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:44:53.576127Z","iopub.execute_input":"2025-08-11T17:44:53.576673Z","iopub.status.idle":"2025-08-11T17:44:58.280262Z","shell.execute_reply.started":"2025-08-11T17:44:53.576650Z","shell.execute_reply":"2025-08-11T17:44:58.279542Z"}},"outputs":[{"name":"stdout","text":"Epoch 01 | Val MAE: 334.6885\nEpoch 02 | Val MAE: 39.8368\nEpoch 03 | Val MAE: 8.9431\nEpoch 04 | Val MAE: 15.9521\nEpoch 05 | Val MAE: 10.8660\nEpoch 06 | Val MAE: 9.1476\nEpoch 07 | Val MAE: 35.3650\nEpoch 08 | Val MAE: 9.4651\nEpoch 09 | Val MAE: 7.0653\nEpoch 10 | Val MAE: 10.0670\nEpoch 11 | Val MAE: 9.5027\nEpoch 12 | Val MAE: 6.2276\nEpoch 13 | Val MAE: 7.1481\nEpoch 14 | Val MAE: 6.0640\nEpoch 15 | Val MAE: 15.6402\nEpoch 16 | Val MAE: 19.2960\nEpoch 17 | Val MAE: 12.6974\nEpoch 18 | Val MAE: 6.5028\nEpoch 19 | Val MAE: 9.5930\nEpoch 20 | Val MAE: 5.7691\nEpoch 21 | Val MAE: 6.2426\nEpoch 22 | Val MAE: 9.0018\nEpoch 23 | Val MAE: 8.5239\nEpoch 24 | Val MAE: 6.8508\nEpoch 25 | Val MAE: 6.1187\nEpoch 26 | Val MAE: 5.9358\nEpoch 27 | Val MAE: 6.2435\nEpoch 28 | Val MAE: 6.1734\nEarly stopping.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# ------------------- FINAL METRICS (Train + Val) -------------------\ntrain_pred, train_true = eval_loader(train_dl)\nval_pred,   val_true   = eval_loader(val_dl)\n\ndef metrics_block(y_t, y_p, label):\n    mae  = mean_absolute_error(y_t, y_p)\n    rmse = mean_squared_error(y_t, y_p, squared=False)\n    r2s = [r2_score(y_t[:, h], y_p[:, h]) for h in range(H)]\n    print(f\"\\n=== {label} Metrics (averaged over {H} horizons) ===\")\n    print(f\"MAE:  {mae:.3f}\")\n    print(f\"RMSE: {rmse:.3f}\")\n    print(f\"R²:   {np.mean(r2s):.3f}\")\n    mae_list  = [mean_absolute_error(y_t[:, h], y_p[:, h]) for h in range(H)]\n    if H >= 12: print(f\"First 12 horizons MAE: {[round(m,3) for m in mae_list[:12]]}\")\n    if H >= 24: print(f\"24h MAE: {mae_list[23]:.3f}\")\n    if H >= 48: print(f\"48h MAE: {mae_list[47]:.3f}\")\n    if H >= 72: print(f\"72h MAE: {mae_list[71]:.3f}\")\n    return mae_list, r2s\n\ntrain_mae_list, train_r2_list = metrics_block(train_true, train_pred, \"Train\")\nval_mae_list,   val_r2_list   = metrics_block(val_true,   val_pred,   \"Validation\")\n\n# Save per-horizon validation metrics\nval_report = pd.DataFrame({\n    \"horizon\": np.arange(1, H+1),\n    \"MAE\": val_mae_list,\n    \"R2\":  val_r2_list\n})\nval_report.to_csv(OUT_DIR / \"tcn_val_per_horizon_metrics.csv\", index=False)\nprint(\"Saved:\", OUT_DIR / \"tcn_val_per_horizon_metrics.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:46:21.081782Z","iopub.execute_input":"2025-08-11T17:46:21.082471Z","iopub.status.idle":"2025-08-11T17:46:21.220215Z","shell.execute_reply.started":"2025-08-11T17:46:21.082445Z","shell.execute_reply":"2025-08-11T17:46:21.219365Z"}},"outputs":[{"name":"stdout","text":"\n=== Train Metrics (averaged over 72 horizons) ===\nMAE:  8.113\nRMSE: 10.728\nR²:   0.339\nFirst 12 horizons MAE: [7.718, 7.597, 7.384, 7.338, 7.176, 7.201, 7.039, 7.04, 6.945, 6.911, 6.865, 6.914]\n24h MAE: 7.138\n48h MAE: 8.535\n72h MAE: 10.118\n\n=== Validation Metrics (averaged over 72 horizons) ===\nMAE:  5.769\nRMSE: 7.229\nR²:   -0.720\nFirst 12 horizons MAE: [5.188, 5.12, 5.105, 5.181, 5.161, 5.186, 5.216, 5.223, 5.157, 5.211, 5.174, 5.18]\n24h MAE: 5.652\n48h MAE: 6.036\n72h MAE: 6.267\nSaved: /kaggle/working/predictions/tcn_val_per_horizon_metrics.csv\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# ------------------- FORECAST NEXT 72 HOURS (ONE CSV) -------------------\nlast_window = df[feat_cols].values[-WINDOW_SIZE:]                     # (T, F)\nlast_window_t = torch.tensor(last_window, dtype=torch.float32).unsqueeze(0).to(device)  # (1, T, F)\n\nmodel.eval()\nwith torch.no_grad():\n    future_pred = model(last_window_t).cpu().numpy().reshape(-1)      # (72,)\n\n# anchor and format times: d/m/yy HH:MM\nlast_valid_time = df.loc[df[TIME_COL].notna(), TIME_COL].iloc[-1]\nstart = last_valid_time.floor(\"H\") + pd.Timedelta(hours=1)\nfuture_times = pd.date_range(start=start, periods=PREDICT_HORIZON, freq=\"h\")\nft = pd.Series(future_times)\nformatted_dt = (\n    ft.dt.day.astype(str) + \"/\" +\n    ft.dt.month.astype(str) + \"/\" +\n    ft.dt.strftime(\"%y\") + \" \" +\n    ft.dt.strftime(\"%H:%M\")\n)\n\nforecast_df = pd.DataFrame({\n    \"datetime\": formatted_dt,\n    \"predicted_aqi_us\": future_pred\n})\npred_csv = OUT_DIR / \"tcn_predicted_aqi_72hrs.csv\"\nforecast_df.to_csv(pred_csv, index=False)\nprint(f\"\\nSaved forecast → {pred_csv}\")\nprint(\"First/last timestamps:\", forecast_df['datetime'].iloc[0], \"→\", forecast_df['datetime'].iloc[-1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:46:28.088137Z","iopub.execute_input":"2025-08-11T17:46:28.088426Z","iopub.status.idle":"2025-08-11T17:46:28.111006Z","shell.execute_reply.started":"2025-08-11T17:46:28.088404Z","shell.execute_reply":"2025-08-11T17:46:28.110261Z"}},"outputs":[{"name":"stdout","text":"\nSaved forecast → /kaggle/working/predictions/tcn_predicted_aqi_72hrs.csv\nFirst/last timestamps: 10/8/25 00:00 → 12/8/25 23:00\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# ------------------- SAVE MODEL + METADATA + SCALER -------------------\nMODEL_PATH   = SAVE_DIR / \"tcn_multioutput_72h.pt\"\nSCALER_PATH  = SAVE_DIR / \"scaler.joblib\"\nMETA_PATH    = SAVE_DIR / \"metadata.json\"\n\ntorch.save(model.state_dict(), MODEL_PATH)\njoblib.dump(scaler, SCALER_PATH)\n\nmeta = {\n    \"features\": feat_cols,\n    \"target_col\": TARGET_COL,\n    \"time_col\": TIME_COL,\n    \"window_size\": WINDOW_SIZE,\n    \"horizon\": PREDICT_HORIZON,\n    \"dayfirst\": True,\n    \"winsor_low\": low,\n    \"winsor_high\": high,\n    \"train_medians\": train_medians,\n    \"scaler_path\": str(SCALER_PATH),\n    \"model\": \"TCN\",\n    \"channels\": CHANNELS,\n    \"kernel_size\": KERNEL_SIZE,\n    \"dropout\": DROPOUT\n}\nMETA_PATH.write_text(json.dumps(meta, indent=2))\nprint(\"Saved model →\", MODEL_PATH)\nprint(\"Saved scaler →\", SCALER_PATH)\nprint(\"Saved metadata →\", META_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-11T17:46:52.890315Z","iopub.execute_input":"2025-08-11T17:46:52.890640Z","iopub.status.idle":"2025-08-11T17:46:52.907548Z","shell.execute_reply.started":"2025-08-11T17:46:52.890618Z","shell.execute_reply":"2025-08-11T17:46:52.906661Z"}},"outputs":[{"name":"stdout","text":"Saved model → /kaggle/working/models/current/tcn_multioutput_72h.pt\nSaved scaler → /kaggle/working/models/current/scaler.joblib\nSaved metadata → /kaggle/working/models/current/metadata.json\n","output_type":"stream"}],"execution_count":14}]}